[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a guy who’s endlessly curious about computer graphics. After spending way too much time in school I completed my Doctorate (available here) and I’ve had the good fortune to work with many brilliant people at several companies, and I’ve contributed a few things that I’m quite proud of, see my Resume for more."
  },
  {
    "objectID": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html",
    "href": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html",
    "title": "CUDA 5 and OpenGL Interop and Dynamic Parallelism",
    "section": "",
    "text": "I seem to revisit this every time every time Nvidia releases a new version of of CUDA."
  },
  {
    "objectID": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#the-good-news",
    "href": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#the-good-news",
    "title": "CUDA 5 and OpenGL Interop and Dynamic Parallelism",
    "section": "The good news…",
    "text": "The good news…\nThe old methods still work, the whole register, map, bind, etc… process I described in my now two year old post Writing to 3D OpenGL textures in CUDA 4.1 with 3D Surface writes still works.  Ideally, the new version number shouldn't introduce any new problems…"
  },
  {
    "objectID": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#the-bad-news",
    "href": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#the-bad-news",
    "title": "CUDA 5 and OpenGL Interop and Dynamic Parallelism",
    "section": "The bad news…",
    "text": "The bad news…\nUnfortunately, if you try to write to a globally scoped CUDA surface from a device-side launched kernel (i.e. a dynamic kernel), nothing will happen. You'll scratch your head and wonder why code that works perfectly fine when launched from the host-side, fails silently when launched device-side.\nI only discovered the reason when I decided to read, word for word, the CUDA Dynamic Parallelism Programming Guide. On page 14, in the \"Textures & Surfaces\" section is this note:\n\nNOTE: The device runtime does not support legacy module-scope (i.e. Fermi-style) textures and surfaces within a kernel launched from the device. Module-scope (legacy) textures may be created from the host and used in device code as for any kernel, but may only be used by a top-level kernel (i.e. the one which is launched from the host).\n\nSo now the old way of dealing with textures is considered \"Legacy\" but apparently not quite deprecated yet.  So don't use them if you plan on using dynamic parallelism. Additional Note: if you so much call a function that attempts to perform a \"Fermi-style\" surface write you're kernel will fail silently, so I highly recommend removing all \"Fermi-style\" textures and surfaces if you plan on using dynamic parallelism.\nSo what's the \"New style\" of textures and surfaces, well also on page 14 is a footnote saying:\n\nDynamically created texture and surface objects are an addition to the CUDA memory model introduced with CUDA 5.0. Please see the CUDA Programming Guide for details.\n\nSo I guess they're called \"Dynamically created textures and surfaces\", which is a mouthful so I'm going to refer to them as \"Kepler-style\" textures and surfaces.  In the actual API they are cudaTextureObject_t and cudaSurfaceObject_t, and you can pass them around as parameters instead of having to declare them at file scope."
  },
  {
    "objectID": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#opengl-interop",
    "href": "posts/2013_04_03 - CUDA 5 and OpenGL Interop and Dynamic Parallelism/index.html#opengl-interop",
    "title": "CUDA 5 and OpenGL Interop and Dynamic Parallelism",
    "section": "OpenGL Interop",
    "text": "OpenGL Interop\nSo now we have two distinct methods for dealing with textures and surfaces, \"Fermi-style\" and \"Kepler-style\", but we only know how graphics interoperability works with the old, might-as-well-be-deprecated, \"Fermi-style\" textures and surfaces.\nAnd while there are some samples showing how the new \"Kepler-style\" textures and surfaces work (see the Bindless Texture sample), all the interop information still seems to target the old \"Fermi-style\" textures and surfaces.  Fortunately, there is some common ground between \"Kepler-style\" and \"Fermi-style\" textures and surfaces, and that common ground is the cudaArray.\nReally, all we have to do is replace Step 6  (binding a cudaArray to a globally scoped surface) from the previous tutorial, with the creation of a cudaSurfaceObject_t. That entails creating a cuda resource description (cudaResourceDesc), and all we have to do is appropriately set the array portion of the cudaResourceDesc to our cudaArray, and then use that cudaResourceDesc to create our cudaSurfaceObject_t, which we can then pass to our kernels, and use to write to our registered and mapped OpenGL textures.\n// Create the cuda resource description\nstruct cudaResourceDesc resoureDescription;\nmemset(&resDesc, 0, sizeof(resoureDescription));\nresDesc.resType = cudaResourceTypeArray;    // be sure to set the resource type to cudaResourceTypeArray\nresDesc.res.array.array = yourCudaArray;    // this is the important bit\n \n// Create the surface object\ncudaSurfaceObject_t writableSurfaceObject = 0;\ncudaCreateSurfaceObject(&writableSurfaceObject, &resoureDescription);\nAnd thats it! Here's hoping the API doesn't change again anytime soon."
  },
  {
    "objectID": "posts/2012_08_06 - OpenGL 4.3 released/index.html",
    "href": "posts/2012_08_06 - OpenGL 4.3 released/index.html",
    "title": "OpenGL 4.3 released",
    "section": "",
    "text": "OpenGL 4.3 has just been released and almost instantly G-Truc (Christophe Riccio) posted another excellent of his excellent OpenGL reviews.  Additionally Mike Bailey has already made available some slides on the new Compute shaders.  And as usual nvidia already has beta drivers available.\nWith over 20 new extensions this is a rather large update for a point release, and while I’m extremely grateful that people have had a chance preview these extensions and provide an alternative to the pain of reading through the extensions themselves (though I will probably do that anyway), I can’t help but wish that this sort of access wasn’t so exclusive. I find the current method of dumping a bunch of new extensions out each SIGGRAPH and shouting “Surprise!” a bit jarring, and more tragically there is no mechanism to allow the OpenGL community at large to provide feedback (unless you are a member of Khronos, I guess).\nIf you look at the extensions I think they lend themselves perfectly to publication on some sort of official Wiki, revision history would be managed automatically, the OpenGL community could provide feedback on the discussion page, and Khronos members would have permission to make the actual edits to the extension. I guess what I am saying, in particular regards to the publication of new extensions, is that I wish OpenGL were a little bit more “open.”\n\nOpenGL 4.3 core specification (with changes)\nGLSL 4.3 specification\nOpenGL 4.3 review Extensions:\nARB_arrays_of_arrays\nARB_clear_buffer_object\nARB_copy_image\nARB_ES3_compatibility\nARB_explicit_uniform_location\nARB_fragment_layer_viewport\nARB_framebuffer_no_attachments\nARB_internalformat_query2\nARB_invalidate_subdata\nARB_program_interface_query\nARB_robust_buffer_access_behavior\nARB_stencil_texturing\nARB_texture_buffer_range\nARB_texture_query_levels\nARB_texture_storage_multisample\nARB_texture_view\nARB_vertex_attrib_binding\nKHR_debug\nARB_compute_shader\nARB_multi_draw_indirect\nARB_shader_image_size\nARB_shader_storage_buffer_object\n\n\n\n\nCitationBibTeX citation:@online{rauwendaal2012,\n  author = {Randall Rauwendaal},\n  title = {OpenGL 4.3 Released},\n  date = {2012-08-06},\n  url = {https://rauwendaal.net/posts/2012_08_06 - OpenGL 4.3 released},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2012. “OpenGL 4.3 Released.” August 6,\n2012. https://rauwendaal.net/posts/2012_08_06\n- OpenGL 4.3 released."
  },
  {
    "objectID": "posts/2012_08_27 - Writing to 3-components buffers using the image API in OpenGL/index.html",
    "href": "posts/2012_08_27 - Writing to 3-components buffers using the image API in OpenGL/index.html",
    "title": "Writing to 3-components buffers using the image API in OpenGL",
    "section": "",
    "text": "As I've describe in detail in another blogpost, atomic counters used in conjunction with the image API and indirect draw buffers can be an excellent and highly performant alternative/replacement to the transformFeedback mechanism (oh wait, I still haven't published that previous blogpost… and performant is not actually a real word).\nAnyway, one place where this atomic counter + image API + indirect buffers approach becomes a little cumbersome, is its slightly less than elegant handling of 3-components buffer texture formats.\nIn the OpenGL 4.2 spec the list of supported buffer texture formats is listed in table 3.15, while the list of supported image unit formats is listed in table 3.21.  The takeaway from comparing these tables is that the supported image unit formats generally omit 3 components formats (other than the GL_R11F_G11F_B10F format).  So how to deal with this if you have a say a GL_RGB32F, or GL_RGB32UI internal format? Well, its actually pretty easy; just bind the proxy texture as the one component version of the internal format (GL_R32F, or GL_R32UI).\nglBindImageTexture(0, buffer_proxy_tex, 0, GL_TRUE, 0, GL_WRITE_ONLY, GL_R32F);\nThen in the shader put a 3-component stride on the atomic counter, then store each component with its own imageStore operation.\nlayout(binding = 0)         uniform atomic_uint atomicCount;\nlayout(rgb32f, binding = 0) uniform imageBuffer positionBuffer;\n \nvoid main()\n{\n  //Some other code...\n \n  int index = 3*int(atomicCounterIncrement(atomicCount));\n \n  imageStore(positionBuffer, index+0, vec4(x));\n  imageStore(positionBuffer, index+1, vec4(y));\n  imageStore(positionBuffer, index+2, vec4(z));\n \n  //Some more code...\n}\nAnd that actually works great, in my experience, replacing transformFeedback with this approach has been as fast or faster despite the multiple imageStore calls.\n\n\n\nCitationBibTeX citation:@online{rauwendaal2012,\n  author = {Randall Rauwendaal},\n  title = {Writing to 3-Components Buffers Using the Image {API}\n    {in~OpenGL}},\n  date = {2012-08-27},\n  url = {https://rauwendaal.net/posts/2012_08_27 - Writing to 3-components buffers using the image API in OpenGL},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2012. “Writing to 3-Components Buffers Using\nthe Image API in OpenGL.” August 27, 2012. https://rauwendaal.net/posts/2012_08_27\n- Writing to 3-components buffers using the image API in OpenGL."
  },
  {
    "objectID": "posts/2013_03_18 - Hybrid Computational Voxelization Using the Graphics Pipeline/index.html",
    "href": "posts/2013_03_18 - Hybrid Computational Voxelization Using the Graphics Pipeline/index.html",
    "title": "Hybrid Computational Voxelization Using the Graphics Pipeline",
    "section": "",
    "text": "Got a paper published in the Journal of Computer Graphics Techniques, see it here\n\nThis paper presents an efficient computational voxelization approach that utilizes the graphics pipeline. Our approach is hybrid in that it performs a precise gap-free computational voxelization, employs fixed-function components of the GPU, and utilizes the stages of the graphics pipeline to improve parallelism. This approach makes use of the latest features of OpenGL and fully supports both conservative and thin-surface voxelization. In contrast to other computational voxelization approaches, our approach is implemented entirely in OpenGL and achieves both triangle and fragment parallelism through its use of geometry and fragment shaders. By exploiting features of the existing graphics pipeline, we are able to rapidly compute accurate scene voxelizations in a manner that integrates well with existing OpenGL applications, is robust across many different models, and eschews the need for complex work/load-balancing schemes.\n\n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {Hybrid {Computational} {Voxelization} {Using} the {Graphics}\n    {Pipeline}},\n  date = {2013-03-18},\n  url = {https://rauwendaal.net/posts/2013_03_18 - Hybrid Computational Voxelization Using the Graphics Pipeline},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “Hybrid Computational Voxelization Using\nthe Graphics Pipeline.” March 18, 2013. https://rauwendaal.net/posts/2013_03_18\n- Hybrid Computational Voxelization Using the Graphics Pipeline."
  },
  {
    "objectID": "posts/2013_08_14 - Bindless textures can “store”/index.html",
    "href": "posts/2013_08_14 - Bindless textures can “store”/index.html",
    "title": "Bindless textures can “store”",
    "section": "",
    "text": "I don't know how I missed this when Nvidia released NV_bindless_texture, I guess because all the samples I saw used bindless textures to demonstrate a ridiculous number of texture reads. But I realized when reading the recently released ARB_bindless_texture extension that they can also be used to \"store,\" or write, to a very large number of textures (using ARB_shader_image_load_store functionality). Which finally gets rid of that extremely pesky MAX_IMAGE_UNITS limitation I've been complaining about. The only downside is that I can no longer run my program at home on my GTX 480.\n \n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {Bindless Textures Can “Store”},\n  date = {2013-08-14},\n  url = {https://rauwendaal.net/posts/2013_08_14 - Bindless textures can “store”},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “Bindless Textures Can\n‘Store’.” August 14, 2013. https://rauwendaal.net/posts/2013_08_14\n- Bindless textures can store."
  },
  {
    "objectID": "posts/2012_06_15 - GLSL Sign Function/index.html",
    "href": "posts/2012_06_15 - GLSL Sign Function/index.html",
    "title": "GLSL sign function",
    "section": "",
    "text": "The GLSL sign function always seems a great way to remove some unnecessary if statements from my shaders, but I never seem to get to use it because I always need to consider zero as either positive or negative, and not its own special value.\nAnyway, I just realized you can accomplish the same thing with the step function.\nstep(0, x)*2 - 1;\nThis will return -1.0 if x < 0, and 1.0 if x >= 0.\nWhich is not terribly readable, hence this overly verbose function\n// returns -1.0 if x < 0, and 1.0 if x >= 0\nfloat signGreaterEqualZero(float x)\n{\n    return step(0, x)*2 - 1;\n}\n\n\n\nCitationBibTeX citation:@online{rauwendaal2011,\n  author = {Randall Rauwendaal},\n  title = {GLSL Sign Function},\n  date = {2011-02-10},\n  url = {https://rauwendaal.net/posts/2012_06_15 - GLSL Sign Function},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2011. “GLSL Sign Function.” February\n10, 2011. https://rauwendaal.net/posts/2012_06_15\n- GLSL Sign Function."
  },
  {
    "objectID": "posts/2013_07_03 - AtomicCounters & IndirectBufferCommands/index.html",
    "href": "posts/2013_07_03 - AtomicCounters & IndirectBufferCommands/index.html",
    "title": "AtomicCounters & IndirectBufferCommands",
    "section": "",
    "text": "I’ve made use of Atomic Counters and Indirect Buffers in the past, but always in the most straightforward manner. I.e. create a dedicated buffer for the atomic counter, and another for the Indirect Command Buffer, increment the counter in a shader then write the Atomic Counter value into the Indirect Command Buffer using the Image API, ending up with a shader that looks something like below.\n#version 420\n\nlayout(location = 0) in ivec3 inputBuffer;\n\nlayout(r32ui, binding = 0) uniform uimageBuffer outputBuffer;\nlayout(r32ui, binding = 1) uniform uimageBuffer indirectArrayCommand;\nlayout(       binding = 0) uniform atomic_uint  atomicCounter;\n\nvoid main()\n{\n  // ...\n  // do some stuff\n  // ...\n\n  if(someCondition == true)\n  {\n    //increment counter\n    int index = int(atomicCounterIncrement(atomicCounter));\n\n    //store stuff in output buffer\n    imageStore(outputBuffer, index, uvec4(someStuff)));\n  }\n\n  memoryBarrier();\n\n  //Store the atomicCounter value to the count (the first element) of the DrawArraysIndirect command\n  imageStore(indirectArrayCommand, 0, uvec4(atomicCounter(atomicCounter)));\n}\nThis works fine, but one annoying thing about this approach is that it consumes an extra image unit (of the max 8 available). Fortunately, it turns out that it is unnecessary to create an extra atomic counter and perform the synchronization with the indirect draw command. It is possible to simply bind the appropriate element of the indirect draw buffer directly to the atomic counter.\n// This binds the count element of the Indirect Array Command Buffer directly as an atomic counter in the shader\n// (no need for copy from dedicated atomic counter)\nglBindBufferRange(GL_ATOMIC_COUNTER_BUFFER,        // Target buffer is the atomic counter\n                  0,                               // Binding point, must match the shader\n                  IndirectArrayCommandBuffer_id,   // Source buffer is the Indirect Draw Command Buffer\n                  0,                               // Offset, 0 for count, 1 for primCount (instances), etc...\n                  sizeof(GLuint));\nThis allows us to get rid of Indirect Buffers image unit binding, which simplifies the shader as shown below. The main reason I’ve found to do this is reduce the number of image units required by the shader, as its very easy to hit the limit of 8.\n#version 420\n\nlayout(location = 0) in ivec3 inputBuffer;\n\nlayout(r32ui, binding = 0) uniform uimageBuffer outputBuffer;\nlayout(       binding = 0) uniform atomic_uint  atomicCounter;\n\nvoid main()\n{\n  // ...\n  // do some stuff\n  // ...\n\n  if(someCondition == true)\n  {\n    //increment counter\n    int index = int(atomicCounterIncrement(atomicCounter));\n\n    //store stuff in output buffer\n    imageStore(outputBuffer, index, uvec4(someStuff)));\n  }\n}\n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {AtomicCounters \\& {IndirectBufferCommands}},\n  date = {2013-07-03},\n  url = {https://rauwendaal.net/posts/2013_07_03 - AtomicCounters & IndirectBufferCommands},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “AtomicCounters &\nIndirectBufferCommands.” July 3, 2013. https://rauwendaal.net/posts/2013_07_03\n- AtomicCounters & IndirectBufferCommands."
  },
  {
    "objectID": "posts/2011_12_02 - Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes/index.html",
    "href": "posts/2011_12_02 - Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes/index.html",
    "title": "Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes",
    "section": "",
    "text": "Edit: For how this works in CUDA 5 see my new post CUDA 5 and OpenGL Interop and Dynamic Parallelism.\nCUDA 4.1 has been released, and with it, and they’ve added support for writing to 3D surfaces. And thanks to some pointers from some very helpful Nvidia engineers (thanks Gernot!), I was able to write to a 3D OpenGL texture with a CUDA kernel, without having to copy any data between the host and the device.\nThe new toolkit has an excellent volumeFiltering sample that shows how to write to 3D surfaces, which was very helpful, but there are still a couple of gotchas to watch out for."
  },
  {
    "objectID": "posts/2011_12_02 - Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes/index.html#conclusion-source",
    "href": "posts/2011_12_02 - Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes/index.html#conclusion-source",
    "title": "Writing to 3D OpenGL textures in CUDA 4.1 with 3D surface writes",
    "section": "Conclusion & Source",
    "text": "Conclusion & Source\nThis is a feature I’ve been looking forward to for quite awhile, and I’m very glad to see it implemented in the newest CUDA release. Hopefully I’ve managed to describe to process clearly enough that other people can avoid the mistakes I made. If you still having trouble make sure you’ve called cudaGLSetGLDevice. I created a very simple source example from an SDK sample, so hopefully it will work/compile if you extract it in your SDK sample directory (C:\\ProgramData\\NVIDIA Corporation\\NVIDIA GPU Computing SDK 4.1\\C\\src)."
  },
  {
    "objectID": "posts/2014_06_14 - Rendering a Screen Covering Triangle in OpenGL (with no buffers)/index.html",
    "href": "posts/2014_06_14 - Rendering a Screen Covering Triangle in OpenGL (with no buffers)/index.html",
    "title": "Rendering a Screen Covering Triangle in OpenGL (with no buffers)",
    "section": "",
    "text": "This one has been on the backlog for ages now.  Anyway, this is an OpenGL adaptation of a clever trick that's been around for quite awhile and described in DirectX terms by Cort Stratton (@postgoodism) in the \"An interesting vertex shader trick\" on #AltDevBlogADay.\nIt describes a method for rendering a triangle that covers the screen with no buffer inputs.  All vertex and texture coordinate information are generated solely from the vertexID.  Unfortunately, because OpenGL uses a right-handed coordinate system while DirectX uses a left-handed coordinate system the same vertexID transformation used for DirectX won't work in OpenGL.  Basically, we need to reverse the order of the triangle vertices so that they are traversed counter-clockwise as opposed to clockwise in the original implementation. So, after a bit of experimentation I came up with the following adaptation for OpenGL:\nvoid main()\n{\n    float x = -1.0 + float((gl_VertexID & 1) << 2);\n    float y = -1.0 + float((gl_VertexID & 2) << 1);\n    gl_Position = vec4(x, y, 0, 1);\n}\nThis transforms the gl_VertexID as follows:\ngl_VertexID=0 -> (-1,-1) gl_VertexID=1 -> ( 3,-1) gl_VertexID=2 -> (-1, 3)\nWe can easily add texture coordinates to this as well:\nout vec2 texCoord;\nvoid main()\n{\n    float x = -1.0 + float((gl_VertexID & 1) << 2);\n    float y = -1.0 + float((gl_VertexID & 2) << 1);\n    texCoord.x = (x+1.0)*0.5;\n    texCoord.y = (y+1.0)*0.5;\n    gl_Position = vec4(x, y, 0, 1);\n}\nWhich is going to provide in that homogeneous clip space region a position value varying from -1 to 1 and texture coordinates varying from 0 to 1 exactly as OpenGL would expect, all without need to any create any buffers. All you have to do is make single call to glDrawArrays and tell it to render 3 vertices:\nglDrawArrays( GL_TRIANGLES, 0, 3 );\nThis draw a triangle that looks like the following:\n\n\n\n\n\nIt's surprising how often this comes in handy, in a later post I'll describe how to adapt this trick to efficiently access the elements of a 3D texture.  It also amuses me greatly that Iñigo Quilez's amazing demo/presentation \"Rendering World's With Two Triangles\" could actually be renamed \"Renderings Worlds With One Triangle.\"\n\n\n\nCitationBibTeX citation:@online{rauwendaal2014,\n  author = {Randall Rauwendaal},\n  title = {Rendering a {Screen} {Covering} {Triangle} in {OpenGL} (with\n    No~Buffers)},\n  date = {2014-06-14},\n  url = {https://rauwendaal.net/posts/2014_06_14 - Rendering a Screen Covering Triangle in OpenGL (with no buffers)},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2014. “Rendering a Screen Covering Triangle in\nOpenGL (with No Buffers).” June 14, 2014. https://rauwendaal.net/posts/2014_06_14\n- Rendering a Screen Covering Triangle in OpenGL (with no buffers)."
  },
  {
    "objectID": "posts/2012_07_18 - OpenGL should support loading shader files/index.html",
    "href": "posts/2012_07_18 - OpenGL should support loading shader files/index.html",
    "title": "OpenGL should support loading shader files",
    "section": "",
    "text": "OpenGL’s shader system is purely string based. Just pass it a couple of strings worth of shader code, compile, link, and go.\nIts not actually that bad, but it gets progressively more annoying the more advanced your shader code gets. It precludes the convenient use of #include, because OpenGL has no idea where that string came from (which directory/file). All the sudden you find yourself terribly missing the ability to factor out some useful utility code into a header file, and just #include it wherever you need it.\nWhy am I griping about this now? Because I just wrote some code that runs through my files line by line looking for #include’s, loading and substituting the correct included source into the original source. Honestly, it wasn’t that bad, but it still *feels* like a hack, and something I really shouldn’t have to do.\nIn reality I was only half done. I had rendered the shader error log meaningless, since the source it had compiled didn’t match the file I was working on. This meant I still had to read the error log generated by OpenGL whenever shader compilation failed, parse that, extract line numbers, and then figure out the correct line and file associated with the error message so that it would actually be meaningful. It works, but again, its annoying, and doesn’t seem like something OpenGL programmers should have to concern themselves with.\nBut what about ARB_shading_language_include?\nYes, I am aware there an extension allowing shader includes, but its all wrong. It is again string based, it introduces 6 OpenGL functions, and requires its own compilation step. A #include should be a 100% preprocessor operation. I don’t want to have to recompile my project just to include a file in my shader. And its not the way OpenGL is headed, prevailingly, more and more is being defined in the shader code itself rather than in the calling OpenGL program (which I think is great).\nIf its not that hard for me to hack into real #include support I imagine the OpenGL driver writers should be able to able handle it as well, and probably do a much better job of it.\nSo, instead of glShaderSource, I propose glShaderFile, which instead of taking in a string of shader source, it takes in a string of a shader file name, from which it extracts the directory such that the shader compiler knows where to look every time #include is used.  Optionally, it could take another string explicitly defining the shader include directory.  Alternately, another version of glShaderSource, say glShaderSourceDir could take a shader string and have a parameter to explicitly define the shader include directory.\nAnyway, that’s my rant.  Its not a huge deal, but I actually think this simple addition would have a fairly large impact on the usability of glsl shaders.\n\n\n\nCitationBibTeX citation:@online{rauwendaal2012,\n  author = {Randall Rauwendaal},\n  title = {OpenGL Should Support Loading Shader Files},\n  date = {2012-07-18},\n  url = {https://rauwendaal.net/posts/2012_07_18 - OpenGL should support loading shader files},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2012. “OpenGL Should Support Loading Shader\nFiles.” July 18, 2012. https://rauwendaal.net/posts/2012_07_18\n- OpenGL should support loading shader files."
  },
  {
    "objectID": "posts/2013_02_07 - GLSL Snippet emulating running atomic average of colors using imageAtomicCompSwap/index.html",
    "href": "posts/2013_02_07 - GLSL Snippet emulating running atomic average of colors using imageAtomicCompSwap/index.html",
    "title": "GLSL Snippet emulating running atomic average of colors using imageAtomicCompSwap",
    "section": "",
    "text": "This is basically straight out of the [Crassin & Greene] chapter from the excellent OpenGL Insights book, which calculates a running average for a RGB voxel color and stores it into a RGBA8 texture (using the alpha component as an access count).  But for whatever reason when I dropped their GLSL snippet into my code I couldn't get it to work correctly.  So, I attempted to rewrite it as simply as possible, and basically ended up with almost the same thing except I used the provided GLSL functions packUnorm4x8 and the unpackUnorm4x8 instead of rolling my own, so it's ever so slightly simpler.\nAnyway, I've verified that this (mostly) works on a GTX 480, I still get a small bit of flickering on a few voxels. Flickering has been fixed, and also works on a GTX Titan.\nvoid imageAtomicAverageRGBA8(layout(r32ui) coherent volatile uimage3D voxels, ivec3 coord, vec3 nextVec3)\n{\n    uint nextUint = packUnorm4x8(vec4(nextVec3,1.0f/255.0f));\n    uint prevUint = 0;\n    uint currUint;\n \n    vec4 currVec4;\n \n    vec3 average;\n    uint count;\n \n    // \"Spin\" while threads are trying to change the voxel\n    while((currUint = imageAtomicCompSwap(voxels, coord, prevUint, nextUint)) != prevUint)\n    {\n        prevUint = currUint;                    // store packed rgb average and count\n        currVec4 = unpackUnorm4x8(currUint);    // unpack stored rgb average and count\n \n        average =      currVec4.rgb;            // extract rgb average\n        count   = uint(currVec4.a*255.0f);      // extract count\n \n        // Compute the running average\n        average = (average*count + nextVec3) / (count+1);\n \n        // Pack new average and incremented count back into a uint\n        nextUint = packUnorm4x8(vec4(average, (count+1)/255.0f));\n    }\n}\nThis works by using the imageAtomicCompSwap function to effectively implement a spinlock, which \"spins\" until all threads trying to access the voxel are done.\nApparently, the compiler can be quite picky about how things like this are written (don't use \"break\" statements), see this thread GLSL loop 'break' instruction not executed for more information, and I can't guarantee this will work on Kepler or any other architectures, and it definitely works fine for both Fermi and Kepler architectures, if anyone can let me know how it works on an AMD architecture I'll add that information here.\nEdit/Update: So I had a few mistakes in my previous implementation which weren't very noticeable in a sparsely tessellated model (like the Dwarf), but became much more noticeable as triangle density increased (like in the curtains and plants of the Sponza model).  Anyway, it turned out I hadn't considered the effects of the packUnorm4x8 and unpackUnorm4x8 functions correctly. The packUnorm4x8 function clamps input components from 0 to 1, so the count updates were getting discarded, and obviously the average was coming out wrong.  Anyway, the solution was to divide by 255 when \"packing\" the count, and multiply by 255 when unpacking.  This method should work with up to 255 threads attempting to write to the same voxel location.\nReferences [Crassin & Greene] Octree-Based Sparse Voxelization Using the GPU Hardware Rasterizer http://www.seas.upenn.edu/%7Epcozzi/OpenGLInsights/OpenGLInsights-SparseVoxelization.pdf\n \n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {GLSL {Snippet} Emulating Running Atomic Average of Colors\n    Using {imageAtomicCompSwap}},\n  date = {2013-02-07},\n  url = {https://rauwendaal.net/posts/2013_02_07 - GLSL Snippet emulating running atomic average of colors using imageAtomicCompSwap},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “GLSL Snippet Emulating Running Atomic\nAverage of Colors Using imageAtomicCompSwap.” February 7, 2013.\nhttps://rauwendaal.net/posts/2013_02_07\n- GLSL Snippet emulating running atomic average of colors using\nimageAtomicCompSwap."
  },
  {
    "objectID": "posts/2013_05_02 - Fixed imageAtomicAverageRGBA8/index.html",
    "href": "posts/2013_05_02 - Fixed imageAtomicAverageRGBA8/index.html",
    "title": "Fixed imageAtomicAverageRGBA8",
    "section": "",
    "text": "So I fixed some issues I had in my previous implementation of imageAtomicAverageRGBA8, see the previous post for an explanation of what I got wrong.  Reposting the corrected code here, and sorry to anyone who was trying to use the broken version.\nAnyway, original credit for this technique should go to Cyril Crassin, whose implementation in [Crassin & Greene] deftly avoided the mistakes I made by implementing his own pack/unpack functions. Still not sure why his implementation doesn't work for me though. Note: I tried to debug these in the Nsight shader debugger and got the message \"Not a debuggable shader\", so either it doesn't support atomics (unverified), or these \"spinlock\" type shaders are too clever for the debugger somehow (for now).\nvoid imageAtomicAverageRGBA8(layout(r32ui) coherent volatile uimage3D voxels, ivec3 coord, vec3 nextVec3)\n{\n    uint nextUint = packUnorm4x8(vec4(nextVec3,1.0f/255.0f));\n    uint prevUint = 0;\n    uint currUint;\n \n    vec4 currVec4;\n \n    vec3 average;\n    uint count;\n \n    //\"Spin\" while threads are trying to change the voxel\n    while((currUint = imageAtomicCompSwap(voxels, coord, prevUint, nextUint)) != prevUint)\n    {\n        prevUint = currUint;                    //store packed rgb average and count\n        currVec4 = unpackUnorm4x8(currUint);    //unpack stored rgb average and count\n \n        average =      currVec4.rgb;            //extract rgb average\n        count   = uint(currVec4.a*255.0f);      //extract count\n \n        //Compute the running average\n        average = (average*count + nextVec3) / (count+1);\n \n        //Pack new average and incremented count back into a uint\n        nextUint = packUnorm4x8(vec4(average, (count+1)/255.0f));\n    }\n}\nReferences [Crassin & Greene] Octree-Based Sparse Voxelization Using the GPU Hardware Rasterizer http://www.seas.upenn.edu/%7Epcozzi/OpenGLInsights/OpenGLInsights-SparseVoxelization.pdf\n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {Fixed {imageAtomicAverageRGBA8}},\n  date = {2013-05-02},\n  url = {https://rauwendaal.net/posts/2013_05_02 - Fixed imageAtomicAverageRGBA8},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “Fixed imageAtomicAverageRGBA8.”\nMay 2, 2013. https://rauwendaal.net/posts/2013_05_02\n- Fixed imageAtomicAverageRGBA8."
  },
  {
    "objectID": "posts/2013_01_09 - Real-time Voxelization Demo/index.html",
    "href": "posts/2013_01_09 - Real-time Voxelization Demo/index.html",
    "title": "Real-time voxelization demo",
    "section": "",
    "text": "CitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {Real-Time Voxelization Demo},\n  date = {2013-02-09},\n  url = {https://rauwendaal.net/posts/2013_01_09 - Real-time Voxelization Demo},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “Real-Time Voxelization Demo.”\nFebruary 9, 2013. https://rauwendaal.net/posts/2013_01_09\n- Real-time Voxelization Demo."
  },
  {
    "objectID": "posts/2013_03_23 - CUDA 5 Enabling Dynamic Parallelism/index.html",
    "href": "posts/2013_03_23 - CUDA 5 Enabling Dynamic Parallelism/index.html",
    "title": "CUDA 5: Enabling Dynamic Parallelism",
    "section": "",
    "text": "I finally got a GPU capable of dynamic parallelism, so I finally decided to mess around with CUDA 5.  But I discovered a couple of configuration options that are required if you want to enable dynamic parallelism.  You'll know you haven't configured things correctly if you attempt to call a kernel from the device and you get the following error message:\n\nptxas : fatal error : Unresolved extern function 'cudaGetParameterBuffer'\n\nNote: this assume you have already selected the appropriate CUDA 5 build customizations for your project\nOpen the project project properties 1. Make sure to set \"Generate Relocatable Device Code\" to \"Yes (-rdc=true)\" 2. Set \"code generation\" to \"compute_35,sm_3″ 3. Finally add \"cudadevrt.lib\" to the CUDA Linker's \"Additional Dependencies\"\n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {CUDA 5: {Enabling} {Dynamic~Parallelism}},\n  date = {2013-03-23},\n  url = {https://rauwendaal.net/posts/2013_03_23 - CUDA 5 Enabling Dynamic Parallelism},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “CUDA 5: Enabling\nDynamic Parallelism.” March 23, 2013. https://rauwendaal.net/posts/2013_03_23\n- CUDA 5 Enabling Dynamic Parallelism."
  },
  {
    "objectID": "posts/2014_08_09 - Rendering Volume Filling Triangles in OpenGL (with no buffers)/index.html",
    "href": "posts/2014_08_09 - Rendering Volume Filling Triangles in OpenGL (with no buffers)/index.html",
    "title": "Rendering Volume Filling Triangles in OpenGL (with no buffers)",
    "section": "",
    "text": "This is the promised follow-up to Rendering a Screen Covering Triangle in OpenGL (with no buffers), except this time the goal is to write a shader that accesses every location in a 3d texture (volume).  We use the same screen covering trick as before to draw a triangle to cover a viewport match to the X and Y dimensions of the volume, and we use instanced rendering to draw repeated triangles for each layer in the Z-dimension.\nThe vertex shader looks the same as before with the addition of the instanceID.\nflat out int instanceID;\n\nvoid main()\n{\n  float x = -1.0 + float((gl_VertexID & 1) << 2);\n  float y = -1.0 + float((gl_VertexID & 2) << 1);\n  instanceID  = gl_InstanceID;\n  gl_Position = vec4(x, y, 0, 1);\n}\nThe fragment shader can then recover the voxel coordinates from gl_FragCoord and the instanceID.\nflat in int instanceID;\n\nvoid main()\n{\n  ivec3 voxelCoord = ivec3(gl_FragCoord.xy, instanceID);\n  voxelOperation(voxelCoord);\n}\nVery similar to drawing the single screen covering triangle, we set our viewport to the XY-dimensions of the volume, bind a junk VAO to make certain graphics drivers happy, and call glDrawArraysInstanced with the Z-dimension of the volume, so that we draw a triangle per-slice of the volume.\nglViewport(0, 0, width, height);\nglBindVertexArray(junkVAO);\nglDrawArraysInstanced(GL_TRIANGLE_STRIP, 0, 3, depth);\nWhich would look sort of like the following:\n\n\n\n\n\nThis can be useful for quickly processing a volume. Initially, I used this as an OpenGL 4.2 fallback (instead of compute shaders) so that I could still use the NSight debugger, until I realized this approach was actually outperforming the compute shader. Of course, when to use compute shaders, and how to use them effectively deserves a post of its own.\n\n\n\nCitationBibTeX citation:@online{rauwendaal2014,\n  author = {Randall Rauwendaal},\n  title = {Rendering {Volume} {Filling} {Triangles} in {OpenGL} (with\n    No~Buffers)},\n  date = {2014-08-09},\n  url = {https://rauwendaal.net/posts/2014_08_09 - Rendering Volume Filling Triangles in OpenGL (with no buffers)},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2014. “Rendering Volume Filling Triangles in\nOpenGL (with No Buffers).” August 9, 2014. https://rauwendaal.net/posts/2014_08_09\n- Rendering Volume Filling Triangles in OpenGL (with no buffers)."
  },
  {
    "objectID": "posts/2008_10_27 - OpenCV (and OpenGL)/index.html",
    "href": "posts/2008_10_27 - OpenCV (and OpenGL)/index.html",
    "title": "OpenCV (and OpenGL)",
    "section": "",
    "text": "So I started using OpenCV for my Computer Vision class, but I didn’t want to give up my OpenGL based framework, and since I had such a hard time finding any hints on how to convert OpenCV Images to OpenGL textures, I’m going to post the technique I used here.  What I did eventually find was this, which didn’t immediately work for me as written.\nSo OpenCV images are stored in these IplImage structs, and they’re actually pretty great because they load just about anything\nIplImage *image = cvLoadImage(\"filename\");\nSo after you create you OpenCV Image, how do you get an OpenGL texture.  Well, OpenCV images are stored as unsigned bytes so so you’re going to want your texturetype to be GL_UNSIGNED_BYTE, and most of the other parameters  to pass to glTexImage2D come right out of the IplImage struct, the only thing to be wary of is swapping the RGB colors, if you don’t, red will look blue, and blue will look red.  So be sure to set internalFormat to GL_RGB, and format to GL_BGR like so\nglTexImage2D(GL_TEXTURE_2D,        //target\n             0,                    //level\n             GL_RGB,               //internalFormat\n             image->width,         //width\n             image->height,        //height\n             0,                    //border\n             GL_BGR,               //format\n             GL_UNSIGNED_BYTE,     //type\n             image->imageData);    //pointer to image data\nOf course, this only works if your Image is color, if your Image is grayscale your going to want to change GL_BGR to GL_LUMINANCE\nglTexImage2D(GL_TEXTURE_2D,        //target\n             0,                    //level\n             GL_RGB,               //internalFormat\n             image->width,         //width\n             image->height,        //height\n             0,                    //border\n             GL_LUMINANCE,         //format\n             GL_UNSIGNED_BYTE,     //type\n             image->imageData);    //pointer to image data\nAnd you could probably change the internal format of the OpenGL texture as well, but I don’t presume to know what you want to do with this.  And one more snippet for good measure, this time loading a color image and converting it to a gray scale image all in OpenCV.\nIplImage *color_image = cvLoadImage(\"filename\");\nIplImage *grayscale = cvCreateImage(cvGetSize(color_image), 8, 1);\ncvCvtColor(color_image, grayscale, CV_BGR2GRAY);\n\n\n\nCitationBibTeX citation:@online{rauwendaal2008,\n  author = {Randall Rauwendaal},\n  title = {OpenCV (and {OpenGL)}},\n  date = {2008-10-27},\n  url = {https://rauwendaal.net/posts/2008_10_27 - OpenCV (and OpenGL)},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2008. “OpenCV (and OpenGL).” October\n27, 2008. https://rauwendaal.net/posts/2008_10_27\n- OpenCV (and OpenGL)."
  },
  {
    "objectID": "posts/2014_05_21 - Readings on physically-based rendering/index.html",
    "href": "posts/2014_05_21 - Readings on physically-based rendering/index.html",
    "title": "Readings on physically-based rendering",
    "section": "",
    "text": "Another nice collections of links and papers too valuable to lose among all my bookmarks.  This time on physically-based rendering, put together by Kostas Anagnostou (@thinkinggamer).\nList maintained and updated over at his blog Interplay of Light:\nhttp://interplayoflight.wordpress.com/2013/12/30/readings-on-physically-based-rendering/\n \n\n\n\nCitationBibTeX citation:@online{rauwendaal2014,\n  author = {Randall Rauwendaal},\n  title = {Readings on Physically-Based Rendering},\n  date = {2014-05-21},\n  url = {https://rauwendaal.net/posts/2014_05_21 - Readings on physically-based rendering},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2014. “Readings on Physically-Based\nRendering.” May 21, 2014. https://rauwendaal.net/posts/2014_05_21\n- Readings on physically-based rendering."
  },
  {
    "objectID": "posts/2014_05_20 - Layered Reflective Shadow Maps for Voxel-based Indirect Illumination/index.html",
    "href": "posts/2014_05_20 - Layered Reflective Shadow Maps for Voxel-based Indirect Illumination/index.html",
    "title": "Layered Reflective Shadow Maps for Voxel-based Indirect Illumination",
    "section": "",
    "text": "So, a lot has happened. I completed my Doctorate, almost moved to Norway, but then ended up moving to Canada instead (Victoria, BC). I now work for the Advanced Technology Group at Intel, where I was very fortunate enough  to have the opportunity to assist a new colleague of mine, Masamichi Sugihara (@masasugihara), with his publication \"Layered Reflective Shadow Maps for Voxel-based Indirect Illumination,\" which has been accepted to HPG 2014.\n\n\nCheck out the preprint here\n\nWe introduce a novel voxel-based algorithm that interactively simulates both diffuse and glossy single-bounce indirect illumination. Our algorithm generates high quality images similar to the reference solution while using only a fraction of the memory of previous methods. The key idea in our work is to decouple occlusion data, stored in voxels, from lighting and geometric data, encoded in a new per-light data structure called layered reflective shadow maps (LRSMs). We use voxel cone tracing for visibility determination and integrate outgoing radiance by performing lookups in a pre-filtered LRSM. Finally we demonstrate that our simple data structures are easy to implement and can be rebuilt every frame to support both dynamic lights and scenes.\n\n\nHire Masamichi!\nDue to some rather shortsighted reorganization, Masasmichi is currently pursuing employment opportunities that will either; allow him to stay in Canada, or return to Japan. If you are interested in hiring a top-notch graphics coder, please get in touch.\n \n\n\n\n\nCitationBibTeX citation:@online{rauwendaal2013,\n  author = {Randall Rauwendaal},\n  title = {Layered {Reflective} {Shadow} {Maps} for {Voxel-based}\n    {Indirect} {Illumination}},\n  date = {2013-05-21},\n  url = {https://rauwendaal.net/posts/2014_05_20 - Layered Reflective Shadow Maps for Voxel-based Indirect Illumination},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2013. “Layered Reflective Shadow Maps for\nVoxel-Based Indirect Illumination.” May 21, 2013. https://rauwendaal.net/posts/2014_05_20\n- Layered Reflective Shadow Maps for Voxel-based Indirect\nIllumination."
  },
  {
    "objectID": "posts/2010_01_12 - How to use CUDA 3.0's new Graphics Interoperability API with OpenGL/index.html",
    "href": "posts/2010_01_12 - How to use CUDA 3.0's new Graphics Interoperability API with OpenGL/index.html",
    "title": "How to use CUDA 3.0’s new Graphics Interoperability API with OpenGL",
    "section": "",
    "text": "It always bothered me that whenever I took a look at using CUDA in my graphics applications there didn’t seem to be an elegant way to use textures from OpenGL with CUDA without doing potentially expensive copies. But that is finally no longer necessary with CUDA 3.0’s new graphics interoperability API.\nThe only real documentation is the online doxygen generated stuff, the best place to start is at the Graphics Interoperability page. Unfortunately there is no documentation for the cudaGraphicsResource struct that all these new functions seem to use. And while there is a API agnostic cudaGraphicsUnregisterResource function, there is no function to actually register a resource unless you look in the API specific modules, which you might first assume, as I did, are deprecated, but it’s only the modules that say [DEPRECATED] real big across the top that are actually deprecated, the new non-deprecated modules simply have a link to the deprecated modules. So for OpenGL you simply have to look at the OpenGL Interoperability page to find the rest of the functions you’ll need, there are similar pages for whatever other API you would like to use.\nSo basically the process is to register a resource, generally a texture or a buffer via the cudaGraphicsGLRegisterImage and cudaGraphicsGLRegisterBuffer functions respectively. These functions assign a valid pointer to your cudaGraphicsResource pointer. Then create a CUDA stream with cudaStreamCreate, map your graphics resource to the CUDA stream with cudaGraphicsMapResources, and at this pointer you can recover a pointer to your texture or buffer data in your CUDA code using the cudaGraphicsSubResourceGetMappedArray and cudaGraphicsResourceGetMappedPointer functions respectively.\nHowever, if you map a texture to a resource you can can only get a pointer to a cudaArray, which is read-only, whereas with a buffer, you can get a pointer to actual data and write to it as well, and since my entire goal in this endeavor was to use CUDA kernels to write to textures as a replacements for my clunky GLSL shaders, thats what I needed to use.\nFortunately there is a workaround called Texture Buffer Objects, which I like to thing of as simply an API to map a Pixel Buffer Object as the data of a Texture. You simply have to remember to create a CUDA stream and map your resources to the CUDA stream before calling any CUDA function that use that resource. So anyway, I’ll just post the most relevant bits of code and hopefully it’ll help someone.\nTest.cpp\n//CUDA graphics resource\ncudaGraphicsResource *resources[1];\n\nGLuint pbo;\nGLuint tbo_tex;\n\nstatic GLuint width  = 512;\nstatic GLuint height = 512;\n\nvoid init_cuda()\n{\n    //Create your Pixel Buffer Object\n    glGenBuffers(1, &pbo);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, width*height*sizeof(float4), NULL, GL_DYNAMIC_DRAW);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    //Create your Texture\n    glGenTextures(1, &_tbo_tex);\n    glBindTexture(GL_TEXTURE_BUFFER_EXT, tbo_tex); //bind Texture\n\n    //Attach Pixel Buffer Object to the Texture\n    glTexBufferEXT(GL_TEXTURE_BUFFER_EXT, GL_RGBA32F_ARB, pbo);\n\n    glBindTexture(GL_TEXTURE_BUFFER_EXT, 0); //unbind Texture\n\n    //Setup CUDA\n    cudaSetDevice(cutGetMaxGflopsDeviceId());\n    cudaGLSetGLDevice(cutGetMaxGflopsDeviceId());\n\n    //Register Pixel Buffer Object as CUDA graphics resource\n    cudaGraphicsGLRegisterBuffer(resources, pbo, cudaGraphicsMapFlagsNone);\n\n    cudaStream_t cuda_stream;\n\n    //Create CUDA stream\n    cudaStreamCreate(&cuda_stream);\n\n    //Map the graphics resource to the CUDA stream\n    cudaGraphicsMapResources(1, resources, cuda_stream);\n\n    //Call CUDA function\n    map_texture(resources[0], width, height);\n\n    //Unmap the CUDA stream\n    cudaGraphicsUnmapResources(1, resources, cuda_stream);\n\n    //Destroy the CUDA stream\n    cudaStreamDestroy(cuda_stream);\n}\n\nvoid cuda_test()    //Call this in your draw loop to animate\n{\n    dim3 blockSize(16, 16);\n    dim3 gridSize(width / blockSize.x, height / blockSize.y);\n\n    cudaStream_t cuda_stream;\n\n    //Create CUDA stream\n    cudaStreamCreate(&cuda_stream);\n\n    //Map the graphics resource to the CUDA stream\n    cudaGraphicsMapResources(1, resources, cuda_stream);\n\n    //Call CUDA function\n    test_cuda(width, height, blockSize, gridSize, cuda_stream);\n\n    //Unmap the CUDA stream\n    cudaGraphicsUnmapResources(1, resources, cuda_stream);\n\n    //Destroy the CUDA stream\n    cudaStreamDestroy(cuda_stream);\n}\nTest.cu\n#ifndef _TEST_CU_\n#define _TEST_CU_\n\n#include\n#include\n#include\n\nfloat4 *cuda_data = NULL;\n\nextern \"C\" void map_texture(cudaGraphicsResource *resource, int w, int h)\n{\n    size_t size;\n    cudaGraphicsResourceGetMappedPointer((void **)(&cuda_data), &size, resource);\n}\n\n__global__ void test_kernel(float4 *cuda_data, int width, int height, int frame_counter)\n{\n    uint x = __umul24(blockIdx.x, blockDim.x) + threadIdx.x;\n    uint y = __umul24(blockIdx.y, blockDim.y) + threadIdx.y;\n    uint i = __umul24(y, width) + x;\n\n    if((x < width) && (y < height))\n    {\n        //Create a checkerboard pattern with 32x32 pixel squares\n        cuda_data[i] = ((((x+frame_counter)/32 + (y+frame_counter)/32 ) & (int)(0x1)) == 0) ? make_float4(1.0, 1.0, 1.0, 1.0) : make_float4(0.0, 0.0, 0.0, 1.0);\n    }\n}\n\nstatic int frame_counter = 0;\n\nextern \"C\" void test_cuda(int width, int height, dim3 blockSize, dim3 gridSize, cudaStream_t &cuda_stream)\n{\n    test_kernel<<>>(cuda_data, width, height, frame_counter);\n    frame_counter++;\n}\n\n#endif\nSince there is no fixed function functionality for drawing texture buffer objects you must write a shader for displaying your buffer, which is pretty easy to do as seen below.\ntbo_shader.glsl\n///////////////////////////////////////////////////////////////////////////////\nVERTEX\n///////////////////////////////////////////////////////////////////////////////\n\nvarying vec2 st;\n\nvoid main()\n{\n    st = gl_MultiTexCoord0.xy;\n    gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex;\n}\n\n///////////////////////////////////////////////////////////////////////////////\nFRAGMENT\n///////////////////////////////////////////////////////////////////////////////\n\n#version 120\n#extension GL_EXT_gpu_shader4 : enable\n\nvarying vec2 st;\n\nuniform samplerBuffer buffer;\nuniform ivec2 dim;\n\nvoid main()\n{\n    int i = int(st.x * float(dim.x));\n    int j = int(st.y * float(dim.y));\n\n    gl_FragData[0] = texelFetch(buffer, i+dim.x*j);\n}\nOf course, there is no reason to display the buffer if your just doing computations on it, and there is no reason you can’t use this technique on Vertex or other buffers. And finally, I don’t have much CUDA experience so I can’t guarantee that I’m not doing anything suboptimal in the above code. I would also recommend wrapping all the CUDA functions cutilSafeCall functions.\n\n\n\nCitationBibTeX citation:@online{rauwendaal2010,\n  author = {Randall Rauwendaal},\n  title = {How to Use {CUDA} 3.0’s New {Graphics} {Interoperability}\n    {API} with {OpenGL}},\n  date = {2010-01-12},\n  url = {https://rauwendaal.net/posts/2010_01_12 - How to use CUDA 3.0’s new Graphics Interoperability API with OpenGL},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRandall Rauwendaal. 2010. “How to Use CUDA 3.0’s New Graphics\nInteroperability API with OpenGL.” January 12, 2010. https://rauwendaal.net/posts/2010_01_12\n- How to use CUDA 3.0’s new Graphics Interoperability API with\nOpenGL."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Papers\n\nM. Sugihara and R. Rauwendaal and M. Salvi, Layered Reflective Shadow Maps for Voxel-based Indirect Illumination, High Performance Graphics, 2014. Available online: https://software.intel.com/en-us/articles/layered-reflective-shadow-maps-for-voxel-based-indirect-illumination.\nR. Rauwendaal and M. Bailey, Hybrid Computational Voxelization Using the Graphics Pipeline, Journal of Computer Graphics Techniques (JCGT), vol. 2, no. 1, 15-37, 2013. Available online: http://jcgt.org/published/0002/01/02/.\nT. Morrison and R. Rauwendaal, A Comparison of Data Parallel Techniques for High Fidelity Smoke, Intel Internal Whitepaper.\nD. S. Long, S. B. Wuest, J. D. Williams, R. Rauwendaal, M. J. Bailey, Contour Planting: A Strategy to Reduce Soil Erosion on Steep Slopes, International Conference on Precision Agriculture. Available online: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.175.9623.\nR. Rauwendaal and M. Bailey, Analyzing Terrain Surfaces to Synthesize and Visualize Optimal-Coverage Tractor Paths for Conservation Farming, Tech Report. Available online: http://web.engr.oregonstate.edu/~mjb/WebMjb/Papers/usda.v4.pdf.\n\n\n\nTheses\n\nR. Rauwendaal, Voxel Based Indirect Illumination using Spherical Harmonics, PhD thesis, Oregon State University, 2013, Available online: http://hdl.handle.net/1957/42266.\nR. Rauwendaal, Hybrid Computational Voxelization Using the Graphics Pipeline, Master’s thesis, Oregon State University, 2012, Available online: http://hdl.handle.net/1957/35463."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rauwendaal.net",
    "section": "",
    "text": "Rendering Volume Filling Triangles in OpenGL (with no buffers)\n\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRendering a Screen Covering Triangle in OpenGL (with no buffers)\n\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReadings on physically-based rendering\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBindless textures can “store”\n\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAtomicCounters & IndirectBufferCommands\n\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2013\n\n\n\n\n\n\n  \n\n\n\n\nLayered Reflective Shadow Maps for Voxel-based Indirect Illumination\n\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed imageAtomicAverageRGBA8\n\n\n\n\n\n\n\n\n\n\n\n\nMay 2, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCUDA 5 and OpenGL Interop and Dynamic Parallelism\n\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2013\n\n\n\n\n\n\n  \n\n\n\n\nCUDA 5: Enabling Dynamic Parallelism\n\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2013\n\n\n\n\n\n\n  \n\n\n\n\nHybrid Computational Voxelization Using the Graphics Pipeline\n\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal-time voxelization demo\n\n\n\n\n\nVideo of a real-time voxel animation demo.\n\n\n\n\n\n\nFeb 9, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLSL Snippet emulating running atomic average of colors using imageAtomicCompSwap\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting to 3-components buffers using the image API in OpenGL\n\n\n\n\n\n\n\n\n\n\n\n\nAug 27, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenGL 4.3 released\n\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenGL should support loading shader files\n\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting to 3D OpenGL textures in CUDA 4.1 with 3D surface writes\n\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLSL sign function\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use CUDA 3.0’s new Graphics Interoperability API with OpenGL\n\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenCV (and OpenGL)\n\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2008\n\n\n\n\n\n\nNo matching items"
  }
]